const OpenAI = require('openai');
const logger = require('../utils/logger');
const messageTemplates = require('../utils/messageTemplates');

class GPTService {
  constructor() {
    this.apiKey = process.env.OPENAI_API_KEY;
    this.model = process.env.OPENAI_MODEL || 'gpt-3.5-turbo';
    this.temperature = parseFloat(process.env.OPENAI_TEMPERATURE) || 0.7;
    this.maxTokens = parseInt(process.env.OPENAI_MAX_TOKENS) || 500;
    
    if (this.apiKey) {
      this.openai = new OpenAI({
        apiKey: this.apiKey,
      });
      console.log('‚úÖ OpenAI configured successfully');
    } else {
      console.warn('‚ö†Ô∏è OpenAI API key not configured - GPT features disabled');
    }

    // Prompt del sistema
    this.systemPrompt = this.getSystemPrompt();
    
    // Cache de respuestas para evitar repetici√≥n
    this.responseCache = new Map();
    this.cacheTimeout = 10 * 60 * 1000; // 10 minutos
  }

  // Generar respuesta autom√°tica
  async generateResponse(userMessage, clientContext = null) {
    try {
      if (!this.openai) {
        return this.getFallbackResponse(userMessage);
      }

      // Verificar cache
      const cacheKey = this.generateCacheKey(userMessage, clientContext);
      const cachedResponse = this.responseCache.get(cacheKey);
      
      if (cachedResponse && Date.now() - cachedResponse.timestamp < this.cacheTimeout) {
        logger.info('Using cached GPT response');
        return cachedResponse.response;
      }

      // Preparar contexto personalizado
      const contextualPrompt = this.buildContextualPrompt(userMessage, clientContext);
      
      // Llamada a OpenAI v4
      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [
          { role: 'system', content: this.systemPrompt },
          { role: 'user', content: contextualPrompt }
        ],
        temperature: this.temperature,
        max_tokens: this.maxTokens,
        presence_penalty: 0.6,
        frequency_penalty: 0.5
      });

      const response = completion.choices[0]?.message?.content?.trim();
      
      if (response) {
        // Guardar en cache
        this.responseCache.set(cacheKey, {
          response: response,
          timestamp: Date.now()
        });

        // Limpiar cache viejo
        this.cleanCache();

        logger.success('GPT response generated successfully');
        return response;
      } else {
        throw new Error('Empty response from OpenAI');
      }

    } catch (error) {
      logger.error('Error generating GPT response:', error.message);
      
      // Respuesta de fallback
      return this.getFallbackResponse(userMessage, clientContext);
    }
  }

  // Generar respuesta para consulta espec√≠fica
  async generateSpecificResponse(type, data) {
    try {
      if (!this.openai) {
        return this.getSpecificFallback(type, data);
      }

      let prompt = '';
      
      switch (type) {
        case 'pricing_inquiry':
          prompt = this.buildPricingPrompt(data);
          break;
        case 'technical_support':
          prompt = this.buildTechnicalSupportPrompt(data);
          break;
        case 'renewal_assistance':
          prompt = this.buildRenewalPrompt(data);
          break;
        case 'general_inquiry':
          prompt = this.buildGeneralInquiryPrompt(data);
          break;
        default:
          prompt = `Responde de manera amigable y profesional a: ${data.message}`;
      }

      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [
          { role: 'system', content: this.systemPrompt },
          { role: 'user', content: prompt }
        ],
        temperature: this.temperature,
        max_tokens: this.maxTokens
      });

      const response = completion.choices[0]?.message?.content?.trim();
      logger.success(`Specific GPT response generated for type: ${type}`);
      
      return response || this.getSpecificFallback(type, data);

    } catch (error) {
      logger.error(`Error generating specific GPT response for ${type}:`, error.message);
      return this.getSpecificFallback(type, data);
    }
  }

  // Analizar intenci√≥n del mensaje
  async analyzeIntent(message) {
    try {
      if (!this.openai) {
        return this.analyzeIntentFallback(message);
      }

      const intentPrompt = `
Analiza la siguiente consulta y determina la intenci√≥n principal:

Mensaje: "${message}"

Responde SOLO con una de estas opciones:
- pricing: Consulta sobre precios o planes
- technical: Problema t√©cnico o soporte
- renewal: Renovaci√≥n o vencimiento
- greeting: Saludo o inicio de conversaci√≥n
- complaint: Queja o reclamo
- general: Consulta general
- other: Otro tipo de consulta

Intenci√≥n:`;

      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [
          { role: 'user', content: intentPrompt }
        ],
        temperature: 0.1,
        max_tokens: 20
      });

      const intent = completion.choices[0]?.message?.content?.trim().toLowerCase();
      
      // Validar respuesta
      const validIntents = ['pricing', 'technical', 'renewal', 'greeting', 'complaint', 'general', 'other'];
      if (validIntents.includes(intent)) {
        return intent;
      } else {
        return 'general';
      }

    } catch (error) {
      logger.error('Error analyzing intent:', error.message);
      return this.analyzeIntentFallback(message);
    }
  }

  // Mejorar mensaje existente
  async enhanceMessage(originalMessage, improvements = []) {
    try {
      if (!this.openai) {
        return originalMessage;
      }

      const enhancePrompt = `
Mejora el siguiente mensaje de atenci√≥n al cliente:

Mensaje original: "${originalMessage}"

Mejoras solicitadas:
${improvements.map(imp => `- ${imp}`).join('\n')}

Reglas:
- Mant√©n el mensaje profesional pero amigable
- Usa emojis apropiadamente
- M√°ximo 500 caracteres
- En espa√±ol peruano

Mensaje mejorado:`;

      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [
          { role: 'user', content: enhancePrompt }
        ],
        temperature: 0.5,
        max_tokens: 200
      });

      const enhanced = completion.choices[0]?.message?.content?.trim();
      return enhanced || originalMessage;

    } catch (error) {
      logger.error('Error enhancing message:', error.message);
      return originalMessage;
    }
  }

  // Generar resumen de conversaci√≥n
  async generateConversationSummary(messages) {
    try {
      if (!this.openai || messages.length === 0) {
        return 'No hay suficiente informaci√≥n para generar un resumen.';
      }

      const conversation = messages.map(msg => 
        `${msg.fromMe ? 'Agente' : 'Cliente'}: ${msg.message}`
      ).join('\n');

      const summaryPrompt = `
Genera un resumen breve de la siguiente conversaci√≥n de atenci√≥n al cliente:

${conversation}

Resumen (m√°ximo 200 caracteres):`;

      const completion = await this.openai.chat.completions.create({
        model: this.model,
        messages: [
          { role: 'user', content: summaryPrompt }
        ],
        temperature: 0.3,
        max_tokens: 100
      });

      return completion.choices[0]?.message?.content?.trim() || 
             'Conversaci√≥n sobre consulta de servicio.';

    } catch (error) {
      logger.error('Error generating conversation summary:', error.message);
      return 'Error generando resumen de conversaci√≥n.';
    }
  }

  // System prompt b√°sico
  getSystemPrompt() {
    return `Eres un asistente virtual especializado en atenci√≥n al cliente para un negocio de suscripciones de streaming (Netflix, Disney+, etc.).

PERSONALIDAD:
- Amigable, profesional y emp√°tico
- Usa emojis apropiados
- Responde en espa√±ol peruano
- Mant√©n un tono conversacional pero profesional

SERVICIOS QUE OFRECES:
- Netflix Premium/Familiar
- Disney+ 
- Prime Video
- HBO Max
- Spotify Premium
- YouTube Premium

INFORMACI√ìN CLAVE:
- Planes desde S/15 mensuales
- Soporte 24/7 por WhatsApp
- Garant√≠a de funcionamiento
- M√©todos de pago: Yape, Plin, transferencia

INSTRUCCIONES:
1. Saluda cordialmente
2. Identifica la necesidad del cliente
3. Ofrece soluciones espec√≠ficas
4. Solicita informaci√≥n si es necesaria
5. Cierra con pr√≥ximos pasos claros

Si no puedes resolver algo, deriva con: "Un especialista te contactar√° pronto para ayudarte con esto üòä"`;
  }

  // M√©todos auxiliares
  buildContextualPrompt(message, clientContext) {
    let prompt = `Mensaje del cliente: "${message}"`;
    
    if (clientContext) {
      prompt += `\n\nInformaci√≥n del cliente:`;
      if (clientContext.name) prompt += `\n- Nombre: ${clientContext.name}`;
      if (clientContext.service) prompt += `\n- Servicio: ${clientContext.service}`;
      if (clientContext.plan) prompt += `\n- Plan: ${clientContext.plan}`;
      if (clientContext.status) prompt += `\n- Estado: ${clientContext.status}`;
      if (clientContext.expiry) prompt += `\n- Vencimiento: ${clientContext.expiry}`;
    }
    
    prompt += `\n\nResponde de manera personalizada y √∫til.`;
    return prompt;
  }

  buildPricingPrompt(data) {
    return `El cliente pregunta sobre precios o planes.
Consulta: "${data.message}"
Servicio de inter√©s: ${data.service || 'No especificado'}

Proporciona informaci√≥n clara sobre nuestros planes de streaming.`;
  }

  buildTechnicalSupportPrompt(data) {
    return `El cliente tiene un problema t√©cnico.
Problema: "${data.message}"
Servicio: ${data.service || 'No especificado'}

Proporciona soluciones paso a paso y mant√©n un tono emp√°tico.`;
  }

  buildRenewalPrompt(data) {
    return `El cliente consulta sobre renovaci√≥n.
Consulta: "${data.message}"
Estado actual: ${data.status || 'No especificado'}

Ayuda con el proceso de renovaci√≥n.`;
  }

  buildGeneralInquiryPrompt(data) {
    return `Consulta general del cliente.
Pregunta: "${data.message}"

Responde de manera informativa y amigable.`;
  }

  getFallbackResponse(message, clientContext = null) {
    // Respuestas autom√°ticas b√°sicas sin GPT
    const lowerMessage = message.toLowerCase();
    
    if (lowerMessage.includes('precio') || lowerMessage.includes('costo') || lowerMessage.includes('plan')) {
      return `¬°Hola! üòä Te ayudo con informaci√≥n sobre nuestros planes:\n\nüì∫ Netflix Premium: S/25/mes\nüè∞ Disney+ Familiar: S/20/mes\nüì¶ Prime Video: S/15/mes\n\n¬øTe interesa alguno en particular?`;
    }
    
    if (lowerMessage.includes('renovar') || lowerMessage.includes('vence') || lowerMessage.includes('pagar')) {
      const name = clientContext?.name || 'Cliente';
      return `¬°Hola ${name}! üëã\n\nPara renovar tu suscripci√≥n puedes:\nüí≥ Transferencia bancaria\nüì± Yape/Plin\nüí∞ Efectivo\n\n¬øCu√°l prefieres? Te env√≠o los datos enseguida üòä`;
    }
    
    if (lowerMessage.includes('problema') || lowerMessage.includes('error') || lowerMessage.includes('no funciona')) {
      return `¬°Hola! Entiendo que tienes un problema t√©cnico üîß\n\nPara ayudarte mejor, necesito saber:\n1Ô∏è‚É£ ¬øQu√© dispositivo usas?\n2Ô∏è‚É£ ¬øQu√© error aparece?\n3Ô∏è‚É£ ¬øCu√°ndo empez√≥?\n\n¬°Te ayudo a solucionarlo! üí™`;
    }
    
    if (lowerMessage.includes('hola') || lowerMessage.includes('buenos') || lowerMessage.includes('buenas')) {
      return `¬°Hola! üëã ¬øEn qu√© puedo ayudarte hoy? Estoy aqu√≠ para resolver tus dudas sobre nuestros servicios üòä`;
    }
    
    // Respuesta gen√©rica
    return `¬°Hola! üëã Gracias por contactarnos.\n\nUn miembro de nuestro equipo te responder√° pronto. Mientras tanto, puedes escribir:\n‚Ä¢ "PRECIOS" para ver planes\n‚Ä¢ "RENOVAR" para informaci√≥n de pagos\n‚Ä¢ "SOPORTE" para ayuda t√©cnica\n\n¬°Estamos aqu√≠ para ayudarte! üòä`;
  }

  getSpecificFallback(type, data) {
    switch (type) {
      case 'pricing_inquiry':
        return 'üìã Nuestros planes:\n‚Ä¢ Netflix Premium: S/25\n‚Ä¢ Disney+: S/20\n‚Ä¢ Prime Video: S/15\n\n¬øTe interesa alguno?';
      case 'technical_support':
        return 'üîß Para soporte t√©cnico:\n1. Reinicia la app\n2. Verifica internet\n3. Reinicia dispositivo\n\n¬øPersiste el problema?';
      case 'renewal_assistance':
        return 'üí≥ Para renovar:\n‚Ä¢ Yape/Plin\n‚Ä¢ Transferencia\n‚Ä¢ Efectivo\n\n¬øCu√°l prefieres?';
      default:
        return '¬°Hola! Un especialista te ayudar√° pronto üòä';
    }
  }

  analyzeIntentFallback(message) {
    const lowerMessage = message.toLowerCase();
    
    if (lowerMessage.includes('precio') || lowerMessage.includes('costo') || lowerMessage.includes('plan')) {
      return 'pricing';
    }
    if (lowerMessage.includes('problema') || lowerMessage.includes('error') || lowerMessage.includes('no funciona')) {
      return 'technical';
    }
    if (lowerMessage.includes('renovar') || lowerMessage.includes('vence') || lowerMessage.includes('pagar')) {
      return 'renewal';
    }
    if (lowerMessage.includes('hola') || lowerMessage.includes('buenos') || lowerMessage.includes('buenas')) {
      return 'greeting';
    }
    if (lowerMessage.includes('mal') || lowerMessage.includes('queja') || lowerMessage.includes('reclamo')) {
      return 'complaint';
    }
    
    return 'general';
  }

  generateCacheKey(message, context) {
    const contextString = context ? JSON.stringify(context) : '';
    return `${message}_${contextString}`.substring(0, 100);
  }

  cleanCache() {
    if (this.responseCache.size > 100) {
      const now = Date.now();
      for (const [key, value] of this.responseCache.entries()) {
        if (now - value.timestamp > this.cacheTimeout) {
          this.responseCache.delete(key);
        }
      }
    }
  }

  // Verificar configuraci√≥n
  isConfigured() {
    return !!this.apiKey;
  }

  // Obtener estad√≠sticas del servicio
  getStats() {
    return {
      configured: this.isConfigured(),
      model: this.model,
      cacheSize: this.responseCache.size,
      maxTokens: this.maxTokens,
      temperature: this.temperature
    };
  }
}

module.exports = new GPTService();